{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gridworld:\n",
    "    def __init__(self):\n",
    "        self.height = 5\n",
    "        self.width = 5\n",
    "        self.actions = ['north', 'south', 'east', 'west']\n",
    "        self.special_states = {'A': (0, 1), 'B': (0, 3)}\n",
    "        self.next_to_states = {\"A'\": (4, 1), \"B'\": (2, 3)}\n",
    "        self.rewards = {'A': 10, 'B': 5}\n",
    "\n",
    "    def reset(self):\n",
    "        return (random.randint(0, 4), random.randint(0, 4))\n",
    "\n",
    "    def step(self, state, action):\n",
    "        if state == self.special_states['A']:\n",
    "            return self.next_to_states[\"A'\"], self.rewards['A']\n",
    "        if state == self.special_states['B']:\n",
    "            return self.next_to_states[\"B'\"], self.rewards['B']\n",
    "\n",
    "        i, j = state\n",
    "        if action == 'north':\n",
    "            i = max(i - 1, 0)\n",
    "        elif action == 'south':\n",
    "            i = min(i + 1, self.height - 1)\n",
    "        elif action == 'west':\n",
    "            j = max(j - 1, 0)\n",
    "        elif action == 'east':\n",
    "            j = min(j + 1, self.width - 1)\n",
    "\n",
    "        return (i, j), 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Gridworld...\n",
      "Grid size: 5x5\n",
      "Special_states = {'A': (0, 1), 'B': (0, 3)}\n",
      "Next_to_states = {\"A'\": (4, 1), \"B'\": (2, 3)}\n",
      "Special_rewards = {'A': 10, 'B': 5}\n",
      "Starting Q-learning with parameters:\n",
      "  γ = 0.9\n",
      "  ε = 0.1\n",
      "  α = 0.2\n",
      "  Episodes = 5000\n",
      "  Steps = 5000\n"
     ]
    }
   ],
   "source": [
    "# Q-learning parameters\n",
    "gamma = 0.9\n",
    "epsilon = 0.1\n",
    "alpha = 0.2\n",
    "episodes = 5000\n",
    "steps = 5000\n",
    "\n",
    "grid = Gridworld()\n",
    "print(\"Initializing Gridworld...\")\n",
    "print(f\"Grid size: {grid.height}x{grid.width}\")\n",
    "print(f\"Special_states = {grid.special_states}\")\n",
    "print(f\"Next_to_states = {grid.next_to_states}\")\n",
    "print(f\"Special_rewards = {grid.rewards}\")\n",
    "print(\"Starting Q-learning with parameters:\")\n",
    "print(f\"  γ = {gamma}\")\n",
    "print(f\"  ε = {epsilon}\")\n",
    "print(f\"  α = {alpha}\")\n",
    "print(f\"  Episodes = {episodes}\")\n",
    "print(f\"  Steps = {steps}\")\n",
    "\n",
    "# Initialize Q-table\n",
    "Q = {(i, j): {a: 0 for a in grid.actions} for i in range(grid.height) for j in range(grid.width)}\n",
    "\n",
    "# Run Q-learning\n",
    "for ep in range(episodes):\n",
    "    state = grid.reset()\n",
    "    for _ in range(steps):\n",
    "        if random.random() < epsilon:\n",
    "            action = random.choice(grid.actions)\n",
    "        else:\n",
    "            action = max(Q[state], key=Q[state].get)\n",
    "\n",
    "        next_state, reward = grid.step(state, action)\n",
    "        best_next = max(Q[next_state].values())\n",
    "        Q[state][action] += alpha * (reward + gamma * best_next - Q[state][action])\n",
    "        state = next_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: Value Function & Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating optimal value function and policy...\n",
      "\n",
      "Optimal Value Function:\n",
      "21.98  24.42  21.98  19.42  17.48\n",
      "19.78  21.98  19.78  17.80  16.02\n",
      "17.80  19.78  17.80  16.02  14.42\n",
      "16.02  17.80  16.02  14.42  12.98\n",
      "14.42  16.02  14.42  12.98  11.68\n",
      "\n",
      "Optimal Policy:\n",
      "east  north  west  north  west\n",
      "north  north  north  west  west\n",
      "north  north  north  north  west\n",
      "north  north  north  north  north\n",
      "north  north  north  north  north\n",
      "\n",
      "Optimal Policy (arrows):\n",
      "→  ↑  ←  ↑  ←\n",
      "↑  ↑  ↑  ←  ←\n",
      "↑  ↑  ↑  ↑  ←\n",
      "↑  ↑  ↑  ↑  ↑\n",
      "↑  ↑  ↑  ↑  ↑\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating optimal value function and policy...\")\n",
    "value_function = np.zeros((grid.height, grid.width))\n",
    "policy = np.empty((grid.height, grid.width), dtype=object)\n",
    "policy_arrows = np.empty((grid.height, grid.width), dtype=object)\n",
    "arrows = {'north':'↑','south':'↓','east':'→','west':'←'}\n",
    "\n",
    "for i in range(grid.height):\n",
    "    for j in range(grid.width):\n",
    "        best_act = max(Q[(i, j)], key=Q[(i, j)].get)\n",
    "        value_function[i, j] = Q[(i, j)][best_act]\n",
    "        policy[i, j] = best_act\n",
    "        policy_arrows[i, j] = arrows[best_act]\n",
    "\n",
    "print(\"\\nOptimal Value Function:\")\n",
    "for row in value_function:\n",
    "    print('  '.join(f\"{v:.2f}\" for v in row))\n",
    "\n",
    "print(\"\\nOptimal Policy:\")\n",
    "for row in policy:\n",
    "    print('  '.join(row))\n",
    "\n",
    "print(\"\\nOptimal Policy (arrows):\")\n",
    "for row in policy_arrows:\n",
    "    print('  '.join(row))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
